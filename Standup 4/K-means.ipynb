{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T21:11:04.957000Z",
     "start_time": "2018-06-29T21:11:04.949000Z"
    }
   },
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:16.755000Z",
     "start_time": "2018-07-03T01:20:16.696000Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import visuals as vs\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "df = pd.read_csv('.\\\\data\\\\orderWithProfit.csv', header=0)\n",
    "# filtered_df = df[df['orderdate'].isnull()]\n",
    "df = df.dropna()\n",
    "df[\"orderDate\"] = df[\"orderDate\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df[\"takenDate\"] = df[\"takenDate\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df[\"shipDate\"] = df[\"shipDate\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df[\"transitDuration\"] = (df[\"shipDate\"]-df[\"takenDate\"])/ np.timedelta64(1, 's')\n",
    "df[\"fulfillDuration\"] = (df[\"shipDate\"]-df[\"orderDate\"])/ np.timedelta64(1, 's')\n",
    "\n",
    "df[\"amount\"] = df[\"red\"]+df[\"blue\"]+df[\"yellow\"]+df[\"black\"]+df[\"white\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T02:13:06.039000Z",
     "start_time": "2018-07-02T02:13:06.035000Z"
    }
   },
   "source": [
    "### Integrate User data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:16.824000Z",
     "start_time": "2018-07-03T01:20:16.759000Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-17bc5bf11c7c>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-17bc5bf11c7c>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    print \"dictionary keys:\",dic.keys()\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "\n",
    "# Combine with customer info\n",
    "df_tmp = pd.read_csv('.\\\\data\\\\orderWithCustomer.csv', header=0)\n",
    "df = pd.merge(df, df_tmp, how='inner', left_on=\"customer\", right_on=\"name\",suffixes=('_x', '_y'),)\n",
    "\n",
    "for key in [\"customer\", \"name\",\"age\", \"sex\", \"city\", \"state\", \"country\",\\\n",
    "                 \"income\", \"credit\",\"education\", \"occupation\",\"orderCount\",\"totalProfit\"]:\n",
    "    dic[key] = {}\n",
    "    ## Add Customer ID (Integer number)\n",
    "    id = 1\n",
    "    for _,name in df[[key]].drop_duplicates()[key].iteritems():\n",
    "        dic[key][name] = id # id starts from 0\n",
    "        id = id+1\n",
    "    df[key] = df[key].apply(lambda x: dic[key][x])\n",
    "\n",
    "    \n",
    "print \"dictionary keys:\",dic.keys()\n",
    "print df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:02:29.737000Z",
     "start_time": "2018-07-01T15:02:29.723000Z"
    }
   },
   "source": [
    "### Features\n",
    "\n",
    "We divide all the features into the following subgroups. Each of the subgroup has its unique source of data. For example. the dataset of \"user\" are derived from the user information and their order records in our system. For each of the subgroup, we have specific target that we want to explore the pattern of. In \"users\", we want to analyze the relationship between the profit of an order and the information of the user who makes the order. In \"Order\", we want to analyze the relationship between the profit of an order and the number of different inventories. In \"DUration\", we want to analyze the relationship between the time spent on transiting and the running data of the robots. In the last dataset, we combine several typical features from each of the dataset and put into a single dataset to see if we can dig out something interesting.\n",
    "\n",
    "#### User\n",
    "customer_id              \n",
    "name            \n",
    "age       \n",
    "sex       \n",
    "city         \n",
    "state            \n",
    "country          \n",
    "income             \n",
    "credit              \n",
    "education    \n",
    "occupation        \n",
    "orderCount       \n",
    "totalProfit   \n",
    "\n",
    "#### Order\n",
    "customer_id\n",
    "\n",
    "green,blue,black,yellow,red,white\n",
    "\n",
    "**amount** = green + blue + black + yellow + red + white\n",
    "\n",
    "#### Duration\n",
    "\n",
    "orderDate,takenDate,shipDate\n",
    "\n",
    "**transitDuration** = shipDate - takenDate\n",
    "\n",
    "**fufillDuration** = shipDate - orderDate\n",
    "\n",
    "shipVisitCount\n",
    "\n",
    "#### Cost, revenue, profit\n",
    "productSales,shipHandleCost\n",
    "\n",
    "**totalRevenue**=productSales + shipHandleCost\n",
    "\n",
    "productCOGS, *orderProcessCost(=10)*, shipVisitCost\n",
    "\n",
    "**totalCost** = productCOGS + *orderProcessCost* + shipVisitcCost\n",
    "\n",
    "**profit**= **totalRevenue** - **totalCost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:16.837000Z",
     "start_time": "2018-07-03T01:20:16.830000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = {}\n",
    "index = {}\n",
    "target = {\"users\":\"profit\",\"order\":\"profit\",\"duration\":\"transitDuration\",\"comples\":\"profit\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:17.385000Z",
     "start_time": "2018-07-03T01:20:16.843000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "index[\"users\"]=[\"age\",\"sex\", \"city\", \"state\",\"country\",\"income\",\"credit\",\"education\",\"occupation\",\"orderCount\",\"totalProfit\",\"profit\"]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[\"users\"] = scaler.fit_transform(df[index[\"users\"]].values)\n",
    "pca = PCA(n_components=2)\n",
    "X[\"users\"] = pca.fit_transform(X[\"users\"])\n",
    "\n",
    "pca_results = vs.pca_results(df[index[\"users\"]], pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:17.820000Z",
     "start_time": "2018-07-03T01:20:17.390000Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "index[\"colors\"]=[\"green\",\"blue\", \"black\", \"yellow\",\"red\",\"white\",\"profit\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[\"colors\"] = scaler.fit_transform(df[index[\"colors\"]].values)\n",
    "pca = PCA(n_components=2)\n",
    "X[\"colors\"] = pca.fit_transform(X[\"colors\"])\n",
    "\n",
    "pca_results = vs.pca_results(df[index[\"colors\"]], pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:18.251000Z",
     "start_time": "2018-07-03T01:20:17.825000Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "index[\"duration\"]=[\"transitDuration\",\"fulfillDuration\",\"shipVisitCount\", \"amount\", \"profit\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[\"duration\"] = scaler.fit_transform(df[index[\"duration\"]].values)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X[\"duration\"] = pca.fit_transform(X[\"duration\"])\n",
    "\n",
    "pca_results = vs.pca_results(df[index[\"duration\"]], pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:18.664000Z",
     "start_time": "2018-07-03T01:20:18.256000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "index[\"price\"]=[\"amount\",\"transitDuration\", \"shipVisitCount\", \"totalRevenue\",\"totalCost\",\"profit\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[\"price\"] = scaler.fit_transform(df[index[\"price\"]].values)\n",
    "pca = PCA(n_components=2)\n",
    "X[\"price\"] = pca.fit_transform(X[\"price\"])\n",
    "\n",
    "pca_results = vs.pca_results(df[index[\"price\"]], pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:19.102000Z",
     "start_time": "2018-07-03T01:20:18.671000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "index[\"complex\"]=[\"age\",\"sex\", \"income\", \"credit\",\\\n",
    "        \"totalProfit\",\"amount\",\"transitDuration\",\\\n",
    "        \"profit\" ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[\"complex\"] = scaler.fit_transform(df[index[\"complex\"]].values)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X[\"complex\"] = pca.fit_transform(X[\"complex\"])\n",
    "\n",
    "pca_results = vs.pca_results(df[index[\"complex\"]], pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection\n",
    "Based on the result of PCA on each of the dataset, we run on the K-means algorithm with cluster number 8. Then, we compare the outcome and choose the best one to perform further analysis. (As our data is limited and noisy, we will not continue analyzing the rest as the result is not reliable enough. )\n",
    "\n",
    "We use two metrics to measure the quality of outcome. One is SSE(Sum of Squared Distance), and another is Calinski and Harabaz score, which is also a internal cluster criterion. The reason we apply both metrics is we observed that the SSE keeps decreasing if K increase, which might be a sign of overfitting. Thus, we introduce this metric to improve the confidendce on K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:19.606000Z",
     "start_time": "2018-07-03T01:20:19.110000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sse = {}\n",
    "chs = {}\n",
    "fig = plt.figure(1, figsize=(10,20))\n",
    "\n",
    "X_keys = X.keys()\n",
    "\n",
    "for i in xrange(4):\n",
    "    #KMeans    \n",
    "    km = KMeans(n_clusters=8,\n",
    "               max_iter=1000)\n",
    "\n",
    "    y_pred = km.fit_predict(X[X_keys[i]])\n",
    "    \n",
    "    #Measuremenet: SSE\n",
    "    sse[i] = km.inertia_\n",
    "    #Measuremenet: Calinski and Harabaz score\n",
    "    chs[i]= calinski_harabaz_score(X[X_keys[i]], y_pred)\n",
    "\n",
    "#Plotting SSE\n",
    "fig = plt.figure(2,figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Dataset#\")\n",
    "plt.ylabel(\"SSE\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(list(chs.keys()), list(chs.values()))\n",
    "plt.xlabel(\"Dataset#\")\n",
    "plt.ylabel(\"C&H Score\")\n",
    "\n",
    "# Chooose the dataset index\n",
    "i_sse = min(sse.items(), key = lambda x:x[1])[0]\n",
    "i_chs = max(chs.items(), key = lambda x:x[1])[0]\n",
    "\n",
    "INDEX = X_keys[i_chs]\n",
    "# INDEX = \"users\"\n",
    "\n",
    "if i_sse == i_chs:\n",
    "    print \"SSH and C&H scores agree on usng dataset \",INDEX\n",
    "else:\n",
    "    print \"SSH and C&H scores conflict, choose C&H result: dataset \",INDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T21:11:59.226000Z",
     "start_time": "2018-06-29T21:11:59.221000Z"
    }
   },
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T21:23:53.297000Z",
     "start_time": "2018-06-29T21:23:53.290000Z"
    }
   },
   "source": [
    "### SSE change with K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:23.568000Z",
     "start_time": "2018-07-03T01:20:19.612000Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = X[INDEX]\n",
    "\n",
    "sse = {}\n",
    "chs = {}\n",
    "fig = plt.figure(1, figsize=(20,40))\n",
    "for k in xrange(1,11):\n",
    "    #KMeans    \n",
    "    km = KMeans(n_clusters=k,\n",
    "               max_iter=1000)\n",
    "\n",
    "    y_pred = km.fit_predict(data)\n",
    "    sse[k] = km.inertia_\n",
    "\n",
    "    #Measuremenet: Calinski and Harabaz score\n",
    "    if k!=1:\n",
    "        chs[k]= calinski_harabaz_score(data, y_pred)\n",
    "    \n",
    "    plt.subplot(5,2,k)\n",
    "    plt.scatter(data[:, 0], data[:, 1],  s=30, c=y_pred, cmap='viridis')\n",
    "    plt.title(\"K Means (K=%d)\"%k, fontsize=14)\n",
    "\n",
    "#Plotting SSE\n",
    "fig = plt.figure(2,figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(list(chs.keys()), list(chs.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"C&H Score\")\n",
    "\n",
    "# Chooose the best K\n",
    "K = max(chs.items(), key = lambda x:x[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:24.079000Z",
     "start_time": "2018-07-03T01:20:23.574000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#KMeans    \n",
    "km = KMeans(n_clusters= K,\n",
    "           max_iter=2000)\n",
    "\n",
    "y_pred = km.fit_predict(data)\n",
    "\n",
    "#Measuremenet: Calinski and Harabaz score\n",
    "print \"Calinski & Harabaz score:\",calinski_harabaz_score(data, y_pred)  \n",
    "print \"SSE:\",km.inertia_ \n",
    "\n",
    "#Plotting\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "plt.scatter(data[:, 0], data[:, 1], c=y_pred, s=30, cmap='viridis')\n",
    "plt.title(\"K Means (K=%d)\"%K, fontsize=14)    \n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine clustered data\n",
    "We plotted the clustered data by groups with the following features:\n",
    "    * Amount and visitCount\n",
    "Amount of items in the order and the number of robots that the order is split to.\n",
    "    * Customer\n",
    "Customers who had order records on the system.\n",
    "    * Gender\n",
    "Gender of the cusotmer who made the order. We plotted both features with duration and their combination. \n",
    "    * Education and occupation\n",
    "Education and occupation of the cusotmer who made the order. We plotted both features with duration and their combination. \n",
    "    * Location\n",
    "Location of the cusotmer who made the order. We plotted both features with duration and their combination. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T21:08:39.031000Z",
     "start_time": "2018-07-02T21:08:39.024000Z"
    }
   },
   "source": [
    "#### Amount, visitCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the plottings below, it can be told that the transit duration has strong relationship with the amount of items in the order. \n",
    "* K = 4,7 shows the range of transit duration locates around 50-100 if the amount is small (less than 20). \n",
    "* K = 2,6,8,9 shows the range of duration is around 100-175 when amount is medium (20 - 30). \n",
    "* K = 3, 5 shows the range of duration is around 150-300 when amount is large (larger than 30). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:25.568000Z",
     "start_time": "2018-07-03T01:20:24.083000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"amount\"])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('amount')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:27.042000Z",
     "start_time": "2018-07-03T01:20:25.575000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"shipVisitCount\"])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('shipVisitCount')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:30.053000Z",
     "start_time": "2018-07-03T01:20:27.049000Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "for k in xrange(K):\n",
    "    fig = plt.figure(1, figsize=(5,5))\n",
    "    ax = Axes3D(fig, rect=[0, 0, 0.95, 1])\n",
    "    ax.scatter(cluster[k][\"amount\"], cluster[k][\"shipVisitCount\"], cluster[k][target[INDEX]],edgecolor=\"k\", s=100)\n",
    "    ax.set_xlabel(\"amount\")\n",
    "    ax.set_ylabel(\"shipVisitCount\")\n",
    "    ax.set_zlabel(target[INDEX])\n",
    "    plt.title(\"K=%d\"%k, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer \n",
    "In this part, we examine whether transit duration changes according to the specific user. \n",
    "And from the plotting of K = 5, it can be told that the extreme long transit time tend happen to some users whose ID nubmer is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:31.447000Z",
     "start_time": "2018-07-03T01:20:30.059000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"customer\"])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('customer')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T03:23:02.860000Z",
     "start_time": "2018-07-02T03:23:02.853000Z"
    }
   },
   "source": [
    "#### Gender\n",
    "From plotting of gender (female = 1, male = 2), it can be told that males in our case tend to wait longer for their items. Also, extreme long durations (more than 200) tend to happen to those males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:34.425000Z",
     "start_time": "2018-07-03T01:20:32.860000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "\n",
    "\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"sex\"])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('sex')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-02T03:28:00.533000Z",
     "start_time": "2018-07-02T03:28:00.526000Z"
    }
   },
   "source": [
    "#### Location of the cusotmer\n",
    "\n",
    "We also tried to dig out the relationship between the location of the user and the time takes for transition of order. It turns out that there is no specific pattern between those two factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:38.939000Z",
     "start_time": "2018-07-03T01:20:37.475000Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "\n",
    "\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"city\"])\n",
    "#     ax.set_xlim([1, id+1])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('city')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T01:20:40.516000Z",
     "start_time": "2018-07-03T01:20:38.945000Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster = {}\n",
    "fig, axes = plt.subplots(K/2+K%2,2,sharex=True, sharey=True,figsize=(10,20))\n",
    "\n",
    "\n",
    "for k in xrange(K):\n",
    "    cluster[k] = df.loc[[i for i in range(len(km.labels_)) if km.labels_[i]==k]]\n",
    "    ax = axes[k/2, k%2]\n",
    "    ax.scatter(cluster[k][target[INDEX]],cluster[k][\"state\"])\n",
    "#     ax.set_xlim([1, id+1])\n",
    "    ax.set_xlabel(target[INDEX])\n",
    "    ax.set_ylabel('state')\n",
    "    ax.set_title('K=%d'%k)\n",
    "    if(k==K-1):\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for HCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "import time as time\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import preprocessing\n",
    "from scipy import ndimage\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "def showdata(X):\n",
    "    # #############################################################################\n",
    "    # Compute clustering\n",
    "    print(\"Compute unstructured hierarchical clustering...\")\n",
    "    \n",
    "    st = time.time()\n",
    "    ward = AgglomerativeClustering(n_clusters=6, linkage='ward').fit(X)\n",
    "    elapsed_time = time.time() - st\n",
    "    label = ward.labels_\n",
    "    print(\"Elapsed time: %.2fs\" % elapsed_time)\n",
    "    print(\"Number of points: %i\" % label.size)\n",
    "    \n",
    "    # #############################################################################\n",
    "    # Plot result\n",
    "    fig = plt.figure()\n",
    "    ax = p3.Axes3D(fig)\n",
    "    ax.view_init(7, -80)\n",
    "    for l in np.unique(label):\n",
    "        ax.scatter(X[label == l, 0], X[label == l, 1], X[label == l, 2],\n",
    "                   color=plt.cm.jet(np.float(l) / np.max(label + 1)),\n",
    "                   s=20, edgecolor='k')\n",
    "    plt.title('Without connectivity constraints (time %.2fs)' % elapsed_time)\n",
    "    \n",
    "    # #############################################################################\n",
    "    # Define the structure A of the data. Here a 10 nearest neighbors\n",
    "    from sklearn.neighbors import kneighbors_graph\n",
    "    connectivity = kneighbors_graph(X, n_neighbors=10, include_self=False)\n",
    "    \n",
    "    # #############################################################################\n",
    "    # Compute clustering\n",
    "    print(\"Compute structured hierarchical clustering...\")\n",
    "    st = time.time()\n",
    "    ward = AgglomerativeClustering(n_clusters=6, connectivity=connectivity,\n",
    "                                   linkage='ward').fit(X)\n",
    "    elapsed_time = time.time() - st\n",
    "    label = ward.labels_\n",
    "    print(\"Elapsed time: %.2fs\" % elapsed_time)\n",
    "    print(\"Number of points: %i\" % label.size)\n",
    "    \n",
    "    # #############################################################################\n",
    "    # Plot result\n",
    "    fig = plt.figure()\n",
    "    ax = p3.Axes3D(fig)\n",
    "    ax.view_init(7, -80)\n",
    "    for l in np.unique(label):\n",
    "        ax.scatter(X[label == l, 0], X[label == l, 1], X[label == l, 2],\n",
    "                   color=plt.cm.jet(float(l) / np.max(label + 1)),\n",
    "                   s=20, edgecolor='k')\n",
    "    plt.title('With connectivity constraints (time %.2fs)' % elapsed_time)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def hca(X, met):\n",
    " #   path = sys.argv[1]\n",
    "    #path = 'data/orderWithCustomer.csv'\n",
    "    #X, y = read_csv(path)\n",
    "\n",
    "    # find distance matrix\n",
    "    d = distance_matrix(X, X)\n",
    "    for link in ('ward', 'average', 'complete'):\n",
    "        clustering = AgglomerativeClustering(linkage=link, n_clusters=10).fit(d)\n",
    "        st = time.time()\n",
    "        label = clustering.labels_\n",
    "        elapsed_time = time.time() - st\n",
    "\n",
    "    # Draw the clustering heatmap based on different methods\n",
    "    sns.set(color_codes=True)\n",
    "    g1 = sns.clustermap(X, method='ward', metric=met, figsize=(5, 8))\n",
    "    g2 = sns.clustermap(X, method='average', metric=met, figsize=(5, 8))\n",
    "    g3 = sns.clustermap(X, method='complete', metric=met, figsize=(5, 8))\n",
    "\n",
    "    # Draw the dendrogram of the clustering based on different methods\n",
    "    plt.figure()\n",
    "    plt.title('Hierarchical Clustering Dendrogram (ward)')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    Z = linkage(X, 'ward')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,\n",
    "        leaf_font_size=8.,\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.title('Hierarchical Clustering Dendrogram (average)')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    Z = linkage(X, 'average')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,\n",
    "        leaf_font_size=8.,\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.title('Hierarchical Clustering Dendrogram (complete)')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    Z = linkage(X, 'complete')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,\n",
    "        leaf_font_size=8.,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = X[\"users\"]\n",
    "data_scaled = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showdata(data)\n",
    "showdata(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HCA Raw Data - Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hca(data,'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HCA Scaled Data - Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hca(data_scaled,'euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HCA Raw Data - Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hca(data,'correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HCA Scaled Data - Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hca(data_scaled,'correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "143px",
    "left": "839.36px",
    "right": "20px",
    "top": "120px",
    "width": "349px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
